# -*- coding: utf-8 -*-
"""캡스톤_리뷰데이터_vector DB만들기.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10D6wUliWvZEp1akIPbf451Za33CSY441

#46860개 리뷰 임베딩 : jhgan/ko-sroberta-multitask
"""

# !pip install -U langchain langchain-community chromadb

import os
os.kill(os.getpid(), 9)

import langchain, langchain_community
print("LangChain 버전:", langchain.__version__)
print("LangChain Community 버전:", langchain_community.__version__)

"""## 리뷰 번호별로 모으기"""

from google.colab import drive, files
import shutil
import pandas as pd


# Mount Drive
drive.mount('/content/drive')

# review_sentence_df = pd.read_excel('/content/drive/MyDrive/ABSA_results/5. review_sentence V7.xlsx')
review_sentence_df = pd.read_excel('/content/drive/MyDrive/Ehwa/캡스톤/5. review_sentence V7.xlsx')

review_sentence_df.head()

review_sentence_df.rename(columns={'joined_sentence': 'sentence'}, inplace=True)

# NaN 값 제거
review_sentence_df = review_sentence_df.dropna(subset=['sentence'])

# sentence 컬럼을 모두 문자열로 변환 (float 등 방지)
review_sentence_df['sentence'] = review_sentence_df['sentence'].astype(str)


# 결과 확인
print(review_sentence_df.head())
print(len(review_sentence_df))

# restaurant_opentime_df = pd.read_excel('/content/drive/MyDrive/ABSA_results/2.opentime_v2.xlsx')
restaurant_opentime_df = pd.read_csv('/content/drive/MyDrive/Ehwa/캡스톤/2.opentime_v2.csv')

restaurant_opentime_df.head()

"""### 감성분석 결과"""

sentiment_df = pd.read_csv('/content/drive/MyDrive/Ehwa/캡스톤/new_predictions.csv')

sentiment_df.head()

merged_review_df = review_sentence_df.merge(
    sentiment_df[['review_no', 'price_pred', 'service_pred', 'taste_pred', 'ambience_pred']],
    on='review_no',
    how='left'
)

merged_review_df.head()



"""### 근처역"""

merged_review_df = merged_review_df.merge(restaurant_opentime_df[['id', 'station']], on='id', how='left')
merged_review_df.head()

"""### 업체 카테고리"""

# from google.colab import drive
# drive.mount('/content/drive')

restaurant_category_df = pd.read_csv('/content/drive/MyDrive/Ehwa/캡스톤/1.id_v2.csv')

restaurant_category_df.head()

merged_review_df = merged_review_df.merge(restaurant_category_df[['id', 'category_1']], on='id', how='left')

merged_review_df.head()

"""## LangChain 문서 리스트로 변환"""

from langchain_core.documents import Document


docs = [
    Document(
        page_content=row["sentence"],  # 리뷰 내용
        metadata={
            "restaurant_id": row["id"],
            "restaurant_name": row["name"],
            "review_no": int(row["review_no"]),
            "rating": float(row["rating"]),
            "date": str(row["date"]),  # 날짜는 문자열로 저장
            "station": str(row["station"]),
            "price_pred": str(row["price_pred"]),
            "service_pred": str(row["service_pred"]),
            "taste_pred": str(row["taste_pred"]),
            "ambience_pred": str(row["ambience_pred"]),
            "category_1": str(row["category_1"])
            }
    )
    for _, row in merged_review_df.iterrows()
]

print(f"문서 개수: {len(docs)}개")
print("예시:", docs[0])

"""## KoSimCSE 임베딩 및 Chroma DB 구축"""

from langchain_core.documents import Document
from langchain_community.vectorstores import Chroma
from sentence_transformers import SentenceTransformer
import numpy as np
import pandas as pd

from langchain_core.documents import Document
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from sentence_transformers import SentenceTransformer
import numpy as np
import pandas as pd



# KoSimCSE 임베딩 모델 (LangChain용)
embedding_model = HuggingFaceEmbeddings(model_name="jhgan/ko-sroberta-multitask")

# Chroma DB 생성 및 저장
chroma_path = "./chroma_review_db_v2"
vector_db = Chroma.from_documents(
    documents=docs,
    embedding=embedding_model,   # 반드시 객체를 전달
    persist_directory=chroma_path
)
vector_db.persist()
print(f"CHROMA 업로드 완료 — 저장 경로: {chroma_path}")

# SentenceTransformer로 직접 임베딩 계산 (엑셀 저장용)
sentence_transformer_model = SentenceTransformer("jhgan/ko-sroberta-multitask")
embeddings = sentence_transformer_model.encode(
    merged_review_df["sentence"].tolist(),
    normalize_embeddings=True,
    batch_size=64,
    show_progress_bar=True
)

# numpy 배열을 문자열로 변환 후 DataFrame에 추가
merged_review_df["embedding"] = [np.array2string(e, separator=",") for e in embeddings]

# 엑셀 저장
output_path = "5. review_sentence V9.xlsx"
merged_review_df.to_excel(output_path, index=False)
print(f" '{output_path}' 파일 저장 완료 (임베딩 포함)")

# Google Drive 백업
# !mkdir -p "/content/drive/MyDrive/ABSA_results"
# !cp -r ./chroma_review_db_v2 "/content/drive/MyDrive/ABSA_results/chroma_review_db_v2"
print("Chroma DB가 Google Drive → ABSA_results 폴더에 백업되었습니다!")

# !cp "/content/5. review_sentence V9.xlsx" "/content/drive/MyDrive/ABSA_results/5. review_sentence V9.xlsx"
print("'5. review_sentence V9.xlsx' 파일이 Google Drive → ABSA_results 폴더에 백업되었습니다!")

final_result_df = pd.read_excel('/content/drive/MyDrive/ABSA_results/5. review_sentence V9.xlsx')

final_result_df

from langchain_community.vectorstores import Chroma

chroma_path = "./chroma_review_db_v2"
vector_db = Chroma(persist_directory=chroma_path, embedding_function=None)
print(vector_db._collection.count())  # 저장된 문서 개수

